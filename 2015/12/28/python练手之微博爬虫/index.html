

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/favicon.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Bipedal Bit">
  <meta name="keywords" content="">
  
    <meta name="description" content="&nbsp;&nbsp;&nbsp; 从半年前声称完成python入门以来，从来没有进行过非API调用的python实战，之前的BP神经网络python版也只是用了pybrain包提供的API而已。惊觉这样下去可能直到我把python语法忘干净都不敢说自己真的掌握了python，但是仍然无所事事拖到大概20天前，室友实验室发下任务要写个Java爬虫，我才决定同时写个python爬虫看看能不能体现下">
<meta property="og:type" content="article">
<meta property="og:title" content="python练手之微博爬虫">
<meta property="og:url" content="https://bipedalbit.net/2015/12/28/python%E7%BB%83%E6%89%8B%E4%B9%8B%E5%BE%AE%E5%8D%9A%E7%88%AC%E8%99%AB/index.html">
<meta property="og:site_name" content="Hacking to the gate!">
<meta property="og:description" content="&nbsp;&nbsp;&nbsp; 从半年前声称完成python入门以来，从来没有进行过非API调用的python实战，之前的BP神经网络python版也只是用了pybrain包提供的API而已。惊觉这样下去可能直到我把python语法忘干净都不敢说自己真的掌握了python，但是仍然无所事事拖到大概20天前，室友实验室发下任务要写个Java爬虫，我才决定同时写个python爬虫看看能不能体现下">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2015-12-28T13:53:49.000Z">
<meta property="article:modified_time" content="2025-05-21T15:42:53.544Z">
<meta property="article:author" content="Bipedal Bit">
<meta property="article:tag" content="python">
<meta property="article:tag" content="网络爬虫">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>python练手之微博爬虫 - Hacking to the gate!</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"bipedalbit.net","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":100,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Hacking to the gate!</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/" target="_self">
                <i class="iconfont icon-link-fill"></i>
                <span>友链</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('https://cdn.minio.bipedalbit.net/bipedalbit-net-images/banner/125633249_p0_resize.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="python练手之微博爬虫"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2015-12-28 21:53" pubdate>
          2015年12月28日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          3.4k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          29 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">python练手之微博爬虫</h1>
            
            
              <div class="markdown-body">
                
                <p>&nbsp;&nbsp;&nbsp; 从半年前声称完成python入门以来，从来没有进行过非API调用的python实战，之前的BP神经网络python版也只是用了pybrain包提供的API而已。惊觉这样下去可能直到我把python语法忘干净都不敢说自己真的掌握了python，但是仍然无所事事拖到大概20天前，室友实验室发下任务要写个Java爬虫，我才决定同时写个python爬虫看看能不能体现下python开发效率的优势。</p>
<span id="more"></span>
<h2 id="1-什么是网络爬虫"><a href="#1-什么是网络爬虫" class="headerlink" title="1. 什么是网络爬虫"></a>1. 什么是网络爬虫</h2><p>&nbsp;&nbsp;&nbsp; 在展开介绍我的python爬虫程序之前先来回顾一下网络爬虫实际上要做些什么事。<br>&nbsp;&nbsp;&nbsp; 从结果来看，网络爬虫是一种<strong>从互相关联的互联网网页上批量获取网页数据的技术手段</strong>。从流程上来看，爬虫程序是一个递归过程：</p>
<ul>
<li>（１）请求网页数据，开始步骤（２）；</li>
<li>（２）解析网页数据，分别解析出<strong>目的数据</strong>和请求下一个网页的<strong>超链接地址</strong>；</li>
<li>（３）如果不再有符合条件的<strong>超链接地址</strong>则结束递归过程，否则回到步骤（１）。</li>
</ul>
<p>&nbsp;&nbsp;&nbsp; 从图论的角度看，如果把网页看成搜索树的状态结点，那么常见的网络爬虫可以看成是一个单一分支的深度优先搜索，当然用于搜索引擎的网络爬虫则常常需要解析出网页中蕴含的多个搜索分支，这就更像我们熟悉的深度优先搜索了。<br>&nbsp;&nbsp;&nbsp; 怎么样，其实很简单吧。计算机技术中最通用的技术，其原理往往是最简单的。</p>
<h2 id="2-为什么需要网络爬虫"><a href="#2-为什么需要网络爬虫" class="headerlink" title="2.为什么需要网络爬虫"></a>2.为什么需要网络爬虫</h2><p>&nbsp;&nbsp;&nbsp; 网络爬虫最常见的应用场景就是获取（遍历）多页数据列表中的所有数据，比如获取网易云音乐某个歌单中的所有音乐地址甚至音乐数据本身，又比如获取豆瓣电影某个主题下的所有电影。<br>&nbsp;&nbsp;&nbsp; 事实上，互联网时代到来之后，大数据时代接踵而至，计算机乃至其他领域的大量实验数据都来自互联网。除了直接从服务器获得数据之外，最普遍的数据获取途径就是通过最大的开放性数据来源WWW（世界范围Web）网络来请求数据了，毕竟比起HTTP协议，其他应用层通讯协议太多太杂太难分析，也不够开放。于是爬虫也成为了一种大量实验数据的获取手段。</p>
<h2 id="3-怎么实现网络爬虫"><a href="#3-怎么实现网络爬虫" class="headerlink" title="3. 怎么实现网络爬虫"></a>3. 怎么实现网络爬虫</h2><p>&nbsp;&nbsp;&nbsp; 我选择了python作为写网络爬虫的语言，事实上据我所知，Java、PHP、C++、Ruby、Perl等我们熟知的绝大多数完善的编程语言都能用来写网络爬虫，或者说，只要有网络通信库的语言都可以用来写网络爬虫。其实相对来说，python的网络通信库还是很发达的，再加上python语言语法的简洁性和数据结构操作天生的灵活性，我觉得用python写网络爬虫没准是最快的。（别说Java可以用封装好的现成爬虫Jar包，没有可比性）<br>&nbsp;&nbsp;&nbsp; 我们通过实例来了解网络爬虫的实现过程。我选择了新浪微博作为爬虫对象，具体来说是将特定新浪微博用户的微博主页作为爬取对象。这里有两点需要注意：<br>&nbsp;&nbsp;&nbsp; 首先，我选择的是<a target="_blank" rel="noopener" href="http://weibo.cn/">微博移动版</a>的页面而非<a target="_blank" rel="noopener" href="http://weibo.com/">PC版</a>的页面作为爬取对象。移动版的页面结构非常简单而且不含任何JavaScript成分，微博数据相对很容易解析出来，而PC版的页面所有的微博数据都由JavaScript填充，虽然不至于找不到数据但是XML结构之外解析数据就几乎要全靠正则表达式了。此外虽然PC版的页面看起来蕴含更多信息，但是许多信息都是通过JavaScript，通过AJAX技术动态向服务器申请来的。如果选择PC版页面作为爬取对象，将大量增加页面解析难度，甚至可能需要让爬虫过程发生嵌套，使整个爬虫流程十分复杂。如果数据能从移动版页面获取，尽量不要选择解析PC版页面。<br>&nbsp;&nbsp;&nbsp; 然后，需要想办法获得登录微博后的cookie，或者cookie的必要字段。微博跟早期的百度贴吧不一样，不登录微博账号的话什么微博数据都看不到。平时我们的浏览器如果没有保存微博登录后的cookie，在访问包含微博数据的页面地址时，HTTP请求会被重定向到登录页面。只有在访问页面时令HTTP请求报文头中携带登录后的cookie，该请求才被服务器认定为合法请求，才会正常的返回被请求的页面。获取cookie有两种途径：</p>
<ul>
<li>通过各种浏览器的HTTP报文抓取插件，从HTTP请求的文件头中提取出现成的cookie；</li>
<li>模拟微博账号登录过程，在登录完成之后的第一次页面访问请求的HTTP报文头中提取出cookie。</li>
</ul>
<h3 id="3-1-python下的HTTP请求"><a href="#3-1-python下的HTTP请求" class="headerlink" title="3.1 python下的HTTP请求"></a>3.1 python下的HTTP请求</h3><p>&nbsp;&nbsp;&nbsp; python下如何完成一次HTTP请求并获得返回的页面数据？哦顺便一说我用的是python2，python3应该区别不大。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> urllib2<br><span class="hljs-built_in">print</span> urllib2.urlopen(<span class="hljs-string">&#x27;www.baidu.com&#x27;</span>).read()<br></code></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp; 完了？完了。是不是很简单？python大法好！开个玩笑不要在意，上面的两行代码只是实现了最简单的默认请求形式及返回数据的获取。实际上urllib2类的urlopen方法参数可以是一个url或者是一个封装好的Request对象，返回值是一个封装好的Response对象。python的网络编程确实很简单直观，我不想细说，至于urllib2的具体的各种相关python API，请自行查阅<a target="_blank" rel="noopener" href="https://docs.python.org/2/library/urllib2.html">手册</a>或者等下看我的源码。</p>
<h3 id="3-2-页面解析"><a href="#3-2-页面解析" class="headerlink" title="3.2 页面解析"></a>3.2 页面解析</h3><p>&nbsp;&nbsp;&nbsp; 页面解析是爬取页面数据后的后续操作，我们实际需要的数据往往蕴含在页面源码之中，最简单粗暴的解析方式就是观察页面源码然后用正则表达式匹配出需要的数据字段。此外既然页面源码的组织方式是HTML，而HTML是一种XML结构，那么我们就可以用一些XML解析工具比如BueatifulSoup、XPath来辅助页面解析。这些工具比较容易寻找到整个HTML文本数据中需要的标签，接下来再用正则表达式简单处理一下，数据就不难获得了。顺便一提，python的正则表达式包叫做re，用法参见<a target="_blank" rel="noopener" href="https://docs.python.org/2/library/re.html">手册</a>。</p>
<h3 id="3-3-模拟登录"><a href="#3-3-模拟登录" class="headerlink" title="3.3 模拟登录"></a>3.3 模拟登录</h3><p>&nbsp;&nbsp;&nbsp; 固然，我们可以偷懒一直选择填入现成的cookie，但是须知，cookie都是有时限或者说寿命的，一定时间后，cookie会过期失效，不再合法。这时就需要重新登录获得一个新的cookie了。虽然cookie过期并没有那么快，但是总是需要有人在侧监视，随时更换cookie来维持比较长的爬虫过程，岂不是显得很low很不自动化？所以大部分比较大、比较正式的爬虫程序都会选择实现特定网站的模拟登录过程。<br>&nbsp;&nbsp;&nbsp; 具体到微博上来，weibo.com即PC版微博网站的登录过程网上有相当多的分析文章，比如<a target="_blank" rel="noopener" href="http://www.douban.com/note/201767245/">这篇</a>、<a target="_blank" rel="noopener" href="http://www.cnblogs.com/myx/archive/2011/10/19/Sina-SSO.html">这篇</a>和<a target="_blank" rel="noopener" href="http://www.360doc.com/content/15/0514/19/13228794_470491590.shtml">这篇</a>。读者需要注意的是，据我所知weibo.com的登录过程微调十分频繁，写一个weibo.com模拟登录可能几个月后就需要根据新浪的微调调整代码了。至于weibo.cn，网上简单的找找似乎没有发现分析文章。但是当时据我猜测，weibo.cn的登录过程应该比weibo.com简单（事实证明确实如此），登录过程微调后修改代码也会更容易。而登录后的cookie，经过我的实验，是通用的。也就是说不论在weibo.cn还是weibo.com，登录后产生的细节各不相同的cookie可能有一个共同部分是用来验证登录状态的（事实再次证明确实如此）。<br>&nbsp;&nbsp;&nbsp; 我使用的HTTP报文抓取插件是firefox下的HttpFox，同类插件还有httpwatch、firefox的自带工具、chrome的自带工具，甚至一些较新版本的IE自带工具。记录登录过程，分析跳转了哪些地址，有几次重定向，期间请求携带了哪些数据，cookie有什么变化。这里我简单说下weibo.cn的登录过程。<br>&nbsp;&nbsp;&nbsp; 总体来说weibo.cn的登录过程分成三个步骤，请求登录页面，获取一些post登录信息的必要参数；post登录信息表单；等待。<br>&nbsp;&nbsp;&nbsp; 登录页面中的action（post目标地址）、加后缀的密码数据键名（如password_2358）和一个叫做vk的数据都是提交登录表单时必要的。<br>&nbsp;&nbsp;&nbsp; 之后就要把表单加工成为可填入Request对象的形式，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">form_data = &#123;<br>	<span class="hljs-string">&#x27;mobile&#x27;</span>: username,<br>	password_name: password,<br>	<span class="hljs-string">&#x27;remeber&#x27;</span>: <span class="hljs-string">&#x27;on&#x27;</span>,<br>	<span class="hljs-string">&#x27;backURL&#x27;</span>: <span class="hljs-string">&#x27;http://weibo.cn/&#x27;</span>,<br>	<span class="hljs-string">&#x27;backTitle&#x27;</span>: <span class="hljs-string">&#x27;微博&#x27;</span>,<br>	<span class="hljs-string">&#x27;tryCount&#x27;</span>: <span class="hljs-string">&#x27;&#x27;</span>,<br>	<span class="hljs-string">&#x27;vk&#x27;</span>: vk,<br>	<span class="hljs-string">&#x27;submit&#x27;</span>: <span class="hljs-string">&#x27;登录&#x27;</span><br>&#125;<br>form_data = urllib.urlencode(form_data)<br></code></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp; 提交表单后新浪服务器会对这一请求进行４次重定向，注意每次重定向都需要提取并重填充cookie字段，因为python的默认重定向处理类不会重填cookie，重写的重定向处理方法如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyRedirectHandler</span>(urllib2.HTTPRedirectHandler):<br>	<span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">	继承urllib2.HTTPRedirectHandler类，封装http_error_302方法。</span><br><span class="hljs-string">	在自动执行重定向发送新的HTTP请求前提取附在请求头中的cookie，</span><br><span class="hljs-string">	提取cookie中模拟登录必需的字段并存储在类成员变量中。</span><br><span class="hljs-string">	&#x27;&#x27;&#x27;</span><br>	<span class="hljs-comment"># 类成员变量，存储以登录状态访问新浪微博必需的cookie字段</span><br>	cookie = <span class="hljs-string">&#x27;&#x27;</span><br><br>	<span class="hljs-keyword">def</span> <span class="hljs-title function_">http_error_302</span>(<span class="hljs-params">self, req, fp, code, msg, headers</span>):<br>		<span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">		添加cookie处理过程，然后调用原http_error_302方法执行自动跳转。</span><br><span class="hljs-string">		&#x27;&#x27;&#x27;</span><br>		cookie = <span class="hljs-built_in">str</span>(headers[<span class="hljs-string">&quot;Set-Cookie&quot;</span>])<br>		<span class="hljs-keyword">if</span> re.search(<span class="hljs-string">&#x27;SUB=.+?;&#x27;</span>, cookie) <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>			MyRedirectHandler.cookie = re.search(<span class="hljs-string">&#x27;SUB=.+?(?=;)&#x27;</span>, cookie).group(<span class="hljs-number">0</span>)<br>		req.add_header(<span class="hljs-string">&quot;Cookie&quot;</span>, cookie)<br>		<span class="hljs-keyword">return</span> urllib2.HTTPRedirectHandler.http_error_302(<span class="hljs-variable language_">self</span>, req, fp, code, msg, headers)<br></code></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp; 最后一次重定向几乎是一个纯JavaScript页面，做的事情是通过JavaScript跳转向一个地址。实验证明最后这一次跳转对于登录过程并没有什么意义，看起来是故弄玄虚。记得我们刚才重写的重定向处理方法吗？我们在重不断重填cookie的过程中也记录了cookie某个字段的更新情况，最后，我们手里有那个字段的最新值。这个cookie字段正是微博登录验证唯一必需的cookie字段。至于我怎么知道是这个字段，对照实验。<br>&nbsp;&nbsp;&nbsp; 是不是比weibo.com的登录过程简单多了？</p>
<h3 id="3-4-可能的改进"><a href="#3-4-可能的改进" class="headerlink" title="3.4 可能的改进"></a>3.4 可能的改进</h3><p>&nbsp;&nbsp;&nbsp; 读者可能发觉了，每次请求的间隔长达几秒，这个爬虫程序与其说是一个高效获取数据的工具，不如说是一个模拟人类操作的脚本而已。简单概括一下就是，爬取页面太慢了。那么如何改进呢？并行化。模拟一个人的访问太慢，那么模拟更多人的访问就好。<br>&nbsp;&nbsp;&nbsp; 并行改进有几个层次，硬件架构的并行化（多核，流水线，长指令等等）、多线程、多进程和分布式。硬件层次的改进对我们这个爬虫程序意义不大，多线程在别的语言中当然可行，可是据我所知，python中的多线程性能收到了限制，python中应该尽量使用多进程。在多进程的基础上，实现完善的分布式通信，就能做分布式并行了。<br>&nbsp;&nbsp;&nbsp; 有读者可能会想到，直接把程序改成多进程的难道不是相当于加大了请求频率而已？是的，确实是这样，所以进程间应该“完全独立”，一个进程被新浪服务器封禁，不应该影响其他进程。这里就涉及一个问题，新浪服务器封禁的是微博账号还是IP地址呢？经过实验答案是IP地址，实际上，目前大多数服务器的反DDoS机制就是封IP。这就好办了，微博账号申请还相对麻烦，可是免费或收费的IP代理却很容易批量获得。比如<a target="_blank" rel="noopener" href="http://www.xicidaili.com/">这里</a>，其中免费的可以直接爬取，肯花钱就能直接获得官方批量代理的接口。当然，广域网分布式具有天然的互异IP，也可以选择使用多台机器，不使用代理。</p>
<p>&nbsp;&nbsp;&nbsp; 全文基本没讲解代码是不是有点过分？这次确实有点偷懒，但是源码里注释写的还是挺详细了。上干货，我把完成的单进程python微博爬虫简单封装了一下，挂在了<a target="_blank" rel="noopener" href="https://github.com/bipedalBit/weibo-crawler">自家git仓库</a>。</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/python/" class="category-chain-item">python</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/python/" class="print-no-link">#python</a>
      
        <a href="/tags/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/" class="print-no-link">#网络爬虫</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>python练手之微博爬虫</div>
      <div>https://bipedalbit.net/2015/12/28/python练手之微博爬虫/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Bipedal Bit</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2015年12月28日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2016/01/02/weibo-cn%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95%E5%99%A8%E7%9A%84python%E9%87%8D%E6%9E%84/" title="weibo.cn模拟登录器的python重构">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">weibo.cn模拟登录器的python重构</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2015/12/05/%E7%94%B1%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E7%B1%BB%E8%84%91%E7%8E%B0%E7%8A%B6%E5%B1%95%E5%BC%80/" title="由人工神经网络和类脑现状展开">
                        <span class="hidden-mobile">由人工神经网络和类脑现状展开</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="waline"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#waline', function() {
      Fluid.utils.createCssLink('https://registry.npmmirror.com/@waline/client/2.15.8/files/dist/waline.css')
      Fluid.utils.createScript('https://registry.npmmirror.com/@waline/client/2.15.8/files/dist/waline.js', function() {
        var options = Object.assign(
          {"serverURL":"https://waline.bipedalbit.net","path":"window.location.pathname","meta":["nick","mail","link"],"requiredMeta":["nick"],"lang":"zh-CN","emoji":["https://cdn.jsdelivr.net/gh/walinejs/emojis/weibo"],"dark":"html[data-user-color-scheme=\"dark\"]","wordLimit":0,"pageSize":10},
          {
            el: '#waline',
            path: window.location.pathname
          }
        )
        Waline.init(options);
        Fluid.utils.waitElementVisible('#waline .vcontent', () => {
          var imgSelector = '#waline .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
      <div class="col-lg-7 mx-auto nopadding-x-md">
        <div class="container custom mx-auto">
          <div style="text-align: center;">
  当前页面浏览量: <span class="waline-pageview-count"></span>
</div>
<script type="module">
  import { pageviewCount } from 'https://unpkg.com/@waline/client@v3/dist/pageview.js';

  pageviewCount({
    serverURL: 'https://comment-plugin.bipedalbit.net/',
    path: window.location.pathname,
    // 可选配置项
    // selector: 'waline-pageview-count',
    // update: true,
  });

  // 等待数据加载完成，检查 span 内容是否为空
  setTimeout(() => {
    const span = document.querySelector('.waline-pageview-count');
    if (!span.textContent.trim()) {
      span.textContent = '1';
    }
  }, 1000); // 1秒后执行，确保数据加载完成
</script>

        </div>
      </div>
    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
<!-- hexo injector body_end start --><script data-pjax src="https://registry.npmmirror.com/oh-my-live2d/latest/files"></script><script>const oml2d = OML2D.loadOml2d({libraryUrls:{"complete":"https://registry.npmmirror.com/oh-my-live2d/latest/files/lib/complete.js","cubism2":"https://registry.npmmirror.com/oh-my-live2d/latest/files/lib/cubism2.js","cubism5":"https://registry.npmmirror.com/oh-my-live2d/latest/files/lib/cubism5.js"},mobileDisplay:true,models:[{"path":"https://cdn.minio.bipedalbit.net/bipedalbit-net-images/live2d-model/HK416-2-destroy/model.json","mobilePosition":[0,-45],"mobileScale":0.06,"mobileStageStyle":{"width":200,"height":240},"motionPreloadStrategy":"IDLE","position":[0,-60],"scale":0.08,"stageStyle":{"width":250,"height":300}}],parentElement:document.body,primaryColor:"var(--btn-bg)",sayHello:false,tips:{style: {"width":200,"height":80,"left":"calc(50% - 10px)","top":"-100px"},mobileStyle: {"width":180,"height":60,"left":"calc(50% - 5px)","top":"-100px"},idleTips:{interval:30000,message:function(){
  return axios.get('https://v1.hitokoto.cn?c=i')
    .then(function (response) {
      return response.data.hitokoto ;
    })
    .catch(function (error) {
      console.error(error);
    });
}
,wordTheDay:true}}});</script><!-- hexo injector body_end end --></body>
</html>
