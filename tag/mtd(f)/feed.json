{
    "version": "https://jsonfeed.org/version/1",
    "title": "Hacking to the gate! • All posts by \"mtd(f)\" tag",
    "description": "Bipedal Bit's blog",
    "home_page_url": "https://bipedalbit.net",
    "items": [
        {
            "id": "https://bipedalbit.net/2015/11/15/%E4%B8%AD%E5%9B%BD%E8%B1%A1%E6%A3%8B%E4%BA%BA%E6%9C%BA%E5%8D%9A%E5%BC%88%E5%AE%9E%E7%8E%B0%E7%BB%83%E4%B9%A0/",
            "url": "https://bipedalbit.net/2015/11/15/%E4%B8%AD%E5%9B%BD%E8%B1%A1%E6%A3%8B%E4%BA%BA%E6%9C%BA%E5%8D%9A%E5%BC%88%E5%AE%9E%E7%8E%B0%E7%BB%83%E4%B9%A0/",
            "title": "中国象棋人机博弈实现练习",
            "date_published": "2015-11-15T13:54:03.000Z",
            "content_html": "<p>&nbsp;&nbsp;&nbsp; 上一篇简略做了棋牌游戏人机博弈的概念铺垫，这一篇文就来贴一下我的初版实现。精力受限，没有像许多前辈那样把Maxmin系的搜索算法（Maxmin、AlphaBeta、Fail-Soft-AlphaBeta、Aspiration、PVS、MTD(f)）全部实现一遍。刚开始我甚至只打算实现一个MTD(f)的搜索核心，因为毕竟最晚出现的算法通常一定程度上是以往算法的集大成者。但是等把MTD(f)实现完，发现里面一层就是个AlphaBeta，于是AlphaBeta的搜索核心作为副产品也存在于实现成果中了。</p>\n<span id=\"more\"></span>\n<p>&nbsp;&nbsp;&nbsp; 我并不打算在这里贴包括Qt5的GUI实现代码在内的所有大概3500行代码（当然其中至少700行可能是注释），主要讲解一下我的实现思路，偶尔贴一些关键代码。完整项目源码我在GitHub建了仓库，这篇文最后会贴地址，读者也可以自己去我Git找找看，毕竟我一共也没建过几个仓库。下面开始正题。</p>\n<h1 id=\"1-需求分析\"><a href=\"#1-需求分析\" class=\"headerlink\" title=\"1 需求分析\"></a>1 需求分析</h1><ul>\n<li>GUI：为了方便人工测试，灵活直观的展现测试结果<del>也方便随时嘚瑟</del>，中国象棋人机博弈程序的实现应该有GUI（图形用户界面）。</li>\n<li>通用部件：应该根据实际需要设计比较高效的、节省空间的、通用的局面表示部件与走法表示部件。</li>\n<li>走法生成器：为了给并行计算和分布式计算做准备，应该设计通用的走法生成器接口。至少实现一个可靠的串行计算的走法生成器。</li>\n<li>搜索核心：为了方便扩展与迭代开发，应该设计通用的搜索核心接口。若干不同版本的走法核心也应该被实现。</li>\n<li>局面评估核心：考虑到短期内难以获得经过结构化解析的对局数据或棋谱，只实现一个参数可在代码中调整的静态局面评估核心，通用局面评估核心接口不予实现，暂时搁置等待重构。</li>\n</ul>\n<h1 id=\"2-概要设计\"><a href=\"#2-概要设计\" class=\"headerlink\" title=\"2 概要设计\"></a>2 概要设计</h1><h2 id=\"2-1-GUI\"><a href=\"#2-1-GUI\" class=\"headerlink\" title=\"2.1 GUI\"></a>2.1 GUI</h2><p>&nbsp;&nbsp;&nbsp; 图形界面中棋盘、棋子的图形是必要组成部分。<br>&nbsp;&nbsp;&nbsp; 此外考虑到人机博弈回合间电脑变动棋子位置太突兀，玩家有时甚至难以察觉棋子位置的变化，应当添加当前选定棋子的标记（对电脑方的棋子来说则是上一步刚被操作过的棋子的标记）。<br>&nbsp;&nbsp;&nbsp; 应当可以选择玩家先手开局或后手开局。<br>&nbsp;&nbsp;&nbsp; 应当有开局按钮。<br>&nbsp;&nbsp;&nbsp; 最好也有悔棋或状态回退按钮。<br>&nbsp;&nbsp;&nbsp; 应当可以在每轮电脑回合前更改电脑使用的搜索核心种类。<br>&nbsp;&nbsp;&nbsp; 应当可以在每轮电脑回合前更改电脑搜索的深度（模拟对局回合数）。<br>&nbsp;&nbsp;&nbsp; 应该显示每轮电脑搜索中评估的局面数量和搜索用时，方便在测试时对算法效率和优化效果进行评估。</p>\n<h2 id=\"2-2-通用部件\"><a href=\"#2-2-通用部件\" class=\"headerlink\" title=\"2.2 通用部件\"></a>2.2 通用部件</h2><p>&nbsp;&nbsp;&nbsp; 最基本的通用部件应该是<em>棋盘位置的表示部件</em>，这个部件首先应当提供位置坐标的设置与查询方法。该部件还可能需要提供一些获取棋盘特定位置属性的方法，以辅助走法生成和局面评估。该部件的变量成员或容器应当进行适当的状态压缩以节省空间。<br>&nbsp;&nbsp;&nbsp; <em>走法表示部件</em>将提供特定走法的属性查询方法，如移动的棋子序号，走法中是否有棋子被吃，移动棋子的起点坐标和终点坐标。走法表示部件将使用棋盘位置表示部件做一些具体的实现。<br>&nbsp;&nbsp;&nbsp; 恰当的<em>局面状态表示部件</em>也是必要的。这个部件将直接为走法生成器和评估核心提供所有棋子的位置、状态查询方法，所有棋子相对位置的属性查询方法，以及所有棋盘特定位置的属性查询方法，棋子位置变更时的局面更新方法，棋子位置变更时的变更回退方法等。毫无疑问局面表示部件将使用棋盘位置表示部件和走法表示部件来实现所需的方法。</p>\n<h2 id=\"2-3-走法生成器\"><a href=\"#2-3-走法生成器\" class=\"headerlink\" title=\"2.3 走法生成器\"></a>2.3 走法生成器</h2><p>&nbsp;&nbsp;&nbsp; 不管计算形式是串行还是并行的，走法生成器应该按照中国象棋规则提供特定局面下合法的所有走法，并装载在一个走法容器中以备查询。合法的走法除需要符合基本的中国象棋行棋规则之外，还应该根据已走局面剔除循环走法。</p>\n<h2 id=\"2-4-搜索核心\"><a href=\"#2-4-搜索核心\" class=\"headerlink\" title=\"2.4 搜索核心\"></a>2.4 搜索核心</h2><p>&nbsp;&nbsp;&nbsp; 搜索核心应该作为游戏程序的主线索，调用走法生成器和局面评估核心对接下来的人机博弈状态做一系列的预演，然后给出相对最好的走法。搜索过程中还应该收集一些程序运行信息，比如评估结点数，搜索时间。搜索每一个新层次时势必要管理搜索树占用的内存空间，应该给出一个可行的空间管理方案。</p>\n<h2 id=\"2-5-局面评估核心\"><a href=\"#2-5-局面评估核心\" class=\"headerlink\" title=\"2.5 局面评估核心\"></a>2.5 局面评估核心</h2><p>&nbsp;&nbsp;&nbsp; 如前所述，暂且只要求实现一个基于少量中国象棋实际经验和主观猜测的评估函数。这个评估函数可能会需要一个类似于走法生成器但有所不同的“棋子影响力覆盖范围生成器”作为工具函数。</p>\n<h1 id=\"3-详细设计\"><a href=\"#3-详细设计\" class=\"headerlink\" title=\"3 详细设计\"></a>3 详细设计</h1><h2 id=\"3-1-GUI\"><a href=\"#3-1-GUI\" class=\"headerlink\" title=\"3.1 GUI\"></a>3.1 GUI</h2><p>&nbsp;&nbsp;&nbsp; Qt5设计GUI有多方便相信用过的读者都有体会，无非就是拖拖控件写写槽函数加点资源调调样式。<br>&nbsp;&nbsp;&nbsp; 本来我想在轮到电脑的回合时间显示一个正在加载时的常见gif图片，但发现这涉及到Qt5的并行计算方式。经过简单的尝试（利用QtConcurrent类）后发现无法在不同线程中顺畅管理相同的控件状态，这可能是资源同步互斥管理的问题（这里相信一些读者会联想到一个关于多线程的笑话：一个程序员遇到了一个问题，想通过多线程来解决它，现在他有两个问题了），于是干脆放弃显示图片的想法了，你将在我的Qt源码中发现我尝试的痕迹。<br>&nbsp;&nbsp;&nbsp; 另一点稍微值得一提的事是，我在准备好一切，要开始写点击棋子的槽函数的时候发现，QLabel控件居然没有Clicked默认事件，看来我是Web应用写多了有点惯性思维了。于是我只好自定义了一个ClickableLabel类，这个类是对QLabel类的封装，重载了基类QWidget的mouseReleaseEvent方法，在方法里发射了一个clicked消息。最后把所有需要点击互动的QLabel提升成了ClickableLabel，并添加了ClickableLabel的clicked消息的槽函数。<br>&nbsp;&nbsp;&nbsp; clickablelable.h：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">ifndef</span> CLICKABLELABEL_H</span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">define</span> CLICKABLELABEL_H</span><br><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;QLabel&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;QWidget&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;QPoint&gt;</span></span><br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ClickableLabel</span> : <span class=\"hljs-keyword\">public</span> QLabel<br>&#123;<br>\tQ_OBJECT<br><span class=\"hljs-keyword\">public</span>:<br>\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">explicit</span> <span class=\"hljs-title\">ClickableLabel</span><span class=\"hljs-params\">(QWidget* parent = <span class=\"hljs-number\">0</span>)</span></span>;<br>\t~<span class=\"hljs-built_in\">ClickableLabel</span>();<br>signals:<br>\t<span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">clicked</span><span class=\"hljs-params\">(ClickableLabel* clickableLabel)</span></span>;<br>\t<span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">clicked</span><span class=\"hljs-params\">(QPoint pos, ClickableLabel* clickableLabel)</span></span>;<br><span class=\"hljs-keyword\">protected</span>:<br>\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">virtual</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">mouseReleaseEvent</span><span class=\"hljs-params\">(QMouseEvent *event)</span></span>;<br>&#125;;<br><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">endif</span> <span class=\"hljs-comment\">// CLICKABLELABEL_H</span></span><br></code></pre></td></tr></table></figure>\n<p>&nbsp;&nbsp;&nbsp; clickablelable.cpp：</p>\n<pre><code class=\"hljs\">#include &quot;clickablelabel.h&quot;\n#include &quot;QMouseEvent&quot;\n\nClickableLabel::ClickableLabel(QWidget* parent)\n\t: QLabel(parent)\n&#123;\n&#125;\n\nClickableLabel::~ClickableLabel()\n&#123;\n&#125;\n\nvoid ClickableLabel::mouseReleaseEvent(QMouseEvent* event)\n&#123;\n\temit clicked(this);\n\temit clicked(event-&gt;pos(), this);\n&#125;\n</code></pre>\n<p>&nbsp;&nbsp;&nbsp; 还挺简单的，不是吗？</p>\n<h2 id=\"3-2-通用部件\"><a href=\"#3-2-通用部件\" class=\"headerlink\" title=\"3.2 通用部件\"></a>3.2 通用部件</h2><h3 id=\"3-2-1-棋盘位置表示部件\"><a href=\"#3-2-1-棋盘位置表示部件\" class=\"headerlink\" title=\"3.2.1 棋盘位置表示部件\"></a>3.2.1 棋盘位置表示部件</h3><p>&nbsp;&nbsp;&nbsp; 我为棋盘位置表示部件实现了一个Position类，只有一个unsigned char型成员变量，８位，一个字节，高四位表示纵坐标即行序号，第四位表示横坐标即列序号，全１有两个方面的含义：对特定棋子来书，当前位置坐标全１表示该棋子已经被吃；对棋盘上特定位置来说，全１表示棋盘上这个位置没有棋子。<br>&nbsp;&nbsp;&nbsp; 因为这个类中的横纵坐标是状态压缩的，需要分别提供横纵坐标的提取／解析方法x()、y()，还有棋子死活／有无的判定及设置方法dead()、kill()。具体实现都是些简单的位运算，比如取第四位用按位与，取高四位用位移。比较局面状态难免要做一系列的棋盘位置比较，所以还实现了“&#x3D;&#x3D;”和“!&#x3D;”符号。<br>&nbsp;&nbsp;&nbsp; 后面在搜索核心的实现有时候会用到置换表，生成hash key需要获取底层的坐标存储数据，所以这个类还有个突兀的友元声明。</p>\n<h3 id=\"3-2-2-走法表示部件\"><a href=\"#3-2-2-走法表示部件\" class=\"headerlink\" title=\"3.2.2 走法表示部件\"></a>3.2.2 走法表示部件</h3><p>&nbsp;&nbsp;&nbsp; 走法表示使用四个成员变量：移动的棋子序号、被吃的棋子序号、原棋盘位置、新棋盘位置，全部使用unsigned char型变量，共４个字节。实现这个类时我偷了个懒，干脆把成员变量访问限定符都定为public了，于是除了空构造函数和一个初始化所有成员变量的重载，只写了一个比较符号“&#x3D;&#x3D;”。没什么特别的。</p>\n<h3 id=\"3-2-3-局面状态表示部件\"><a href=\"#3-2-3-局面状态表示部件\" class=\"headerlink\" title=\"3.2.3 局面状态表示部件\"></a>3.2.3 局面状态表示部件</h3><p>&nbsp;&nbsp;&nbsp; 这个部件还比较有意思。实际上，写游戏初版时，因为走法生成器，搜索核心或评估核心内部实现过程不顺心，曾经一度重构通用部件，其中也伴随着通用部件新需求的不断提出。作为直接向三大模块提供服务的部件，局面状态表示部件的修改最为频繁。<br>&nbsp;&nbsp;&nbsp; 资料提出的中国象棋棋盘状态存储模型有：</p>\n<ul>\n<li>用32颗棋子的棋盘分布（32*10*9个比特）来保存局面状态；</li>\n<li>用14种棋子的棋盘分布（14*10*9个比特）来保存局面状态；</li>\n<li>用10*9个棋盘位置上32颗棋子的互斥存在标识（10*9*5个比特）来保存局面状态；</li>\n<li>用10*9个棋盘位置上14种棋子的互斥存在标识（10*9*4个比特）来保存局面状态；</li>\n<li>用32颗棋子的坐标值（32*8个比特）来保存局面状态。</li>\n</ul>\n<p>&nbsp;&nbsp;&nbsp; 可以看出，上述模型占用空间的大小依次递减。如果比较占用空间大小，第五种模型显然最优。但是实现走法生成器和评估核心时，需要对棋子相对位置上的棋子有无、棋子归属进行大量查询。如果每次针对特定棋盘位置的棋子查询都通过遍历32颗棋子来完成，何况每颗棋子都需要对若干个相对位置做棋子查询，尤其是車、炮这种自由度很大的棋子，恐怕随着搜索树的展开，将累计很大的时间开销。<br>&nbsp;&nbsp;&nbsp; 那么如果换用第四种模型呢？特定棋子相对位置的状态可以直接查询到了，同类查询的时间开销降到了第五种模型的1&#x2F;32。那么如果选用第四种模型，除了稍多一些的空间开销，有没有做出别的牺牲呢？当我们想要查询特定棋子的坐标，不再能够直接查到了，我们需要遍历整个棋盘来寻找一颗棋子，还需要标记这颗棋子是否同类棋子（同归属方、同兵种）中我们需要的那一颗。同类查询的时间开销变成了原来的90倍以上。这并不是一个典型的、合算的空间换时间型优化。<br>&nbsp;&nbsp;&nbsp; 我们重新思考一下局面表示部件在搜索过程中的实际使用情况，不难发现，如果把当前局面作为一个引用参数引入搜索核心类，那么整个搜索过程中，不论采用怎样的局面表示模型，不论对当前局面状态做了多少次更新和回退，空间开销的差别其实微乎其微。真正对空间开销起明显作用的是走法表示部件的数据结构。想到这里不禁觉得一阵无力感袭来，局面状态表示部件的状态压缩是不太有意义的。<br>&nbsp;&nbsp;&nbsp; 那么我们现在可以专注于提高局面状态表示部件中各种方法的时间效率而无视空间开销了。于是我用了一个双向索引，即同时在部件中使用第一种模型和第五种模型。这样不管按棋子序号查询坐标还是按特定坐标查询棋盘位置状态，都可以以常数级的时间开销完成查询过程。当然还实现了许多为三大模块提供服务的方法，还需要记录局面评分和主动权归属。<br>&nbsp;&nbsp;&nbsp; State.h：</p>\n<pre><code class=\"hljs\">#ifndef _STATE_H_\n#define _STATE_H_\n\n#include &quot;Position.h&quot;\n#include &quot;Move.h&quot;\n\n/* 棋子序号 */\n/* 红帅 */\n#define R_KING 0\n/* 红仕序号起点（序号个数2） */\n#define R_MANDARIN 1\n/* 红相序号起点（序号个数2） */\n#define R_ELEPHANT 3\n/* 红马序号起点（序号个数2） */\n#define R_KNIGHT 5\n/* 红車序号起点（序号个数2） */\n#define R_ROOK 7\n/* 红炮序号起点（序号个数2） */\n#define R_CANNON 9\n/* 红兵序号起点（序号个数5） */\n#define R_PAWN 11\n/* 红子序号起点 */\n#define R_BEGIN R_KING\n/* 红子序号终点 */\n#define R_END R_PAWN+4\n/* 黑将 */\n#define B_KING 16\n/* 黑士序号起点（序号个数2） */\n#define B_MANDARIN 17\n/* 黑象序号起点（序号个数2） */\n#define B_ELEPHANT 19\n/* 黑马序号起点（序号个数2） */\n#define B_KNIGHT 21\n/* 黑車序号起点（序号个数2） */\n#define B_ROOK 23\n/* 黑炮序号起点（序号个数2） */\n#define B_CANNON 25\n/* 黑卒序号起点（序号个数5） */\n#define B_PAWN 27\n/* 黑子序号起点 */\n#define B_BEGIN B_KING\n/* 黑子序号终点 */\n#define B_END B_PAWN+4\n/* 坐标数组中表示棋子已被吃 */\n#define DEAD 0xff\n/* 棋子数组中表示坐标无棋子占用 */\n#define NONE DEAD\n\n/* 局面状态类：32+90=122字节 */\n/* 这个类负责记录局面状态，包括局面的棋子索引的状态和坐标索引的状态。 */\n/* 坐标索引的状态提供坐标优先的快速状态查询； */\n/* 棋子索引的状态提供棋子优先的快速状态查询。 */\nclass State\n&#123;\npublic:\n\t/* 当前局面下红方是否持有行动权 */\n\tbool RTurn;\n\t/* 根据中国象棋规则初始化局面状态 */\n\tState();\n\t/* 根据走法更新棋盘状态 */\n\tvoid move(const Move &amp;m);\n\t/* 还原按走法还原更新前的棋盘状态 */\n\tvoid undo(const Move &amp;m);\n\t/* 获取特定棋子行号，即棋子y坐标 */\n\tunsigned char y(unsigned char chessNo) const;\n\t/* 获取特定棋子列号，即棋子x坐标 */\n\tunsigned char x(unsigned char chessNo) const;\n\t/* 获取特定坐标上的棋子序号或空序号 */\n\tunsigned char getNo(unsigned char x, unsigned char y) const;\n\t/* 存活判定 */\n\tbool isAlive(unsigned char chessNo) const;\n\t/* 红子判定 */\n\tbool isRed(unsigned char chessNo) const;\n\t/* 黑子判定 */\n\tbool isBlack(unsigned char chessNo) const;\n\t/* 友方判定 */\n\tbool isFriend(unsigned char chessNo1, unsigned char chessNo2) const;\n\t/* 特定棋子相对位置处是否有子 */\n\tbool relExist(unsigned char chessNo, char x, char y) const;\n\t/* 特定棋子相对位置处是否有红子 */\n\tbool relRedExist(unsigned char chessNo, char x, char y) const;\n\t/* 特定棋子相对位置处是否有黑子 */\n\tbool relBlackExist(unsigned char chessNo, char x, char y) const;\n\t/* 判断当前棋局是否已经结束，即一方的将/帅已经被吃 */\n\tbool isDone() const;\n\t/* 定义一个相等运算符，unordered_map要用 */\n\tbool operator == (const State state) const;\n\t/* 允许KeyHash类访问私有成员 */\n\tfriend class KeyHash;\nprivate:\n\t/* 使用双向索引，加快两个方向的查询速度 */\n\t/* 棋子序号索引的坐标数组：32字节 */\n\tPosition posList[32];\n\t/* 棋盘坐标索引的棋子数组：90字节 */\n\t/* 二维数组的每个单元为一个8位整型数，用来表示坐标占用情况 */\n\t/* 即与坐标数组通用的棋子序号和一个额外的表示空的序号0xff */\n\tunsigned char board[10][9];\n&#125;;\n\n#endif\n</code></pre>\n<p>&nbsp;&nbsp;&nbsp; 具体方法实现都很简单，就不在这贴代码了。</p>\n<h2 id=\"3-3-走法生成器\"><a href=\"#3-3-走法生成器\" class=\"headerlink\" title=\"3.3 走法生成器\"></a>3.3 走法生成器</h2><p>&nbsp;&nbsp;&nbsp; 这是我认为中国象棋游戏中实现起来最繁琐的一个模块了，这里无法回避中国象棋零散的行棋规则。<br>&nbsp;&nbsp;&nbsp; 将／帅除了直面对方将／帅时可以飞过去吃掉对方，平时只能在己方的“帅府”九宫格中向没有己方棋子且不超出棋盘的位置做下列４种移动：</p>\n<ul>\n<li><code>(x, y) -&gt; (x-1, y)</code></li>\n<li><code>(x, y) -&gt; (x+1, y)</code></li>\n<li><code>(x, y) -&gt; (x, y-1)</code></li>\n<li><code>(x, y) -&gt; (x, y+1)</code></li>\n</ul>\n<p>&nbsp;&nbsp;&nbsp; 士／仕只能在己方“帅府”九宫格中向没有己方棋子且不超出棋盘的位置做下列４种移动：</p>\n<ul>\n<li><code>(x, y) -&gt; (x-1, y-1)</code></li>\n<li><code>(x, y) -&gt; (x+1, y-1)</code></li>\n<li><code>(x, y) -&gt; (x-1, y+1)</code></li>\n<li><code>(x, y) -&gt; (x+1, y+1)</code></li>\n</ul>\n<p>&nbsp;&nbsp;&nbsp; 象／相只能在己方阵地的五行内，在不被“遮象眼”的情况下“走田字”，即向没有己方棋子且不超出棋盘的位置做下列４种尝试：</p>\n<ul>\n<li>(x-1, y-1)处无子则<code>(x, y) -&gt; (x-2, y-2)</code></li>\n<li>(x+1, y-1)处无子则<code>(x, y) -&gt; (x+2, y-2)</code></li>\n<li>(x-1, y+1)处无子则<code>(x, y) -&gt; (x-2, y+2)</code></li>\n<li>(x+1, y+1)处无子则<code>(x, y) -&gt; (x+2, y+2)</code></li>\n</ul>\n<p>&nbsp;&nbsp;&nbsp; 马只能在不被“別马腿”的情况下“走日字”，即向没有己方棋子且不超出棋盘的位置做下列８种尝试：</p>\n<ul>\n<li>(x-1, y)处无子则<code>(x, y) -&gt; (x-2, y-1), (x, y) -&gt; (x-2, y+1)</code></li>\n<li>(x+1, y)处无子则<code>(x, y) -&gt; (x+2, y-1), (x, y) -&gt; (x+2, y+1)</code></li>\n<li>(x, y-1)处无子则<code>(x, y) -&gt; (x-1, y-2), (x, y) -&gt; (x+1, y-2)</code></li>\n<li>(x, y+1)处无子则<code>(x, y) -&gt; (x-1, y+2), (x, y) -&gt; (x+1, y+2)</code></li>\n</ul>\n<p>&nbsp;&nbsp;&nbsp; 車可以在上、下、左、右四个方向上在不超出棋盘又无棋子阻挡“视线”的前提下尝试移动任意距离，当遇到第一颗阻挡“视线”的棋子，如果棋子归属方不同，还可以吃子，取代那颗棋子的位置。<br>&nbsp;&nbsp;&nbsp; 炮有两种移动模式，即非吃子或吃子。非吃子模式下，炮可以在上、下、左、右四个方向上在不超出棋盘又无棋子阻挡“视线”的前提下尝试移动任意距离；吃子模式下，炮首先要在上、下、左、右四个方向上找到一颗阻挡“视线”的棋子，然后跳过这颗棋子，继续向前寻找阻挡“视线”的第二颗棋子，如果找到阻挡视线的第一颗和第二颗棋子，且第二颗棋子归属方不同，可以吃掉第二颗棋子，取代它的位置。<br>&nbsp;&nbsp;&nbsp; 兵／卒有两种行棋情况，在离开己方阵地的五行之前，只能在前方没有己方棋子的情况下向对方阵地移动一格；在离开己方阵地即进入敌方阵地后，向没有己方棋子且不超出棋盘的位置向前一格、向左一格或向右一格移动。<br>&nbsp;&nbsp;&nbsp; 此外，还要引入局面记录参数，剔除造成重复局面的走法。<br>&nbsp;&nbsp;&nbsp; 文字描述都这么麻烦，程序就更麻烦了，串行的走法生成器我写了700+行，虽然我的缩进比较“宽松”，注释比较多，还是很长了。并行版本如果用多线程还得管理线程队列、线程池，创建线程、监视线程、管理共享资源、做同步互斥什么的，恐怕会更长。多进程也一样。</p>\n<h2 id=\"3-4-搜索核心\"><a href=\"#3-4-搜索核心\" class=\"headerlink\" title=\"3.4 搜索核心\"></a>3.4 搜索核心</h2><h3 id=\"3-4-1-搜索核心通用接口\"><a href=\"#3-4-1-搜索核心通用接口\" class=\"headerlink\" title=\"3.4.1 搜索核心通用接口\"></a>3.4.1 搜索核心通用接口</h3><p>&nbsp;&nbsp;&nbsp; 本着引入复杂类型变量时能用引用或指针就不复制变量的原则，搜索核心通用接口定义了许多成员变量。一个局面状态表示部件currentState用来复制当前状态，我复制了整个部件而非引入一个引用，是因为如果使用引用，构造类的时候不太方便，同样要增加开销。我想过使用指针，但是发现遍历State类成员时会一直报错，没能调顺，只得放弃。同样的理由，局面记录也进行了复制，但是我发现只进行浅复制就不会报错，也就没有深究。估值核心我使用了指针，因为估值核心的实例化发生在搜索核心的构造函数中。此外还有当前搜索深度变量、最大搜索深度变量、最佳走法、评估结点数即搜索树的叶结点树和搜索时间。<br>&nbsp;&nbsp;&nbsp; 搜索核心通用接口定义的方法不多，构造函数中只实例化了评估核心，析构函数负责销毁评估核心，此外只有一个搜索函数和一个获得最佳走法的只读方法。</p>\n<h3 id=\"3-4-2-MTD-f\"><a href=\"#3-4-2-MTD-f\" class=\"headerlink\" title=\"3.4.2 MTD(f)\"></a>3.4.2 MTD(f)</h3><p>&nbsp;&nbsp;&nbsp; 搜索核心的一个实现是MTD(f)算法。MTD(f)的最外层是一个迭代深化的过程，具体说就是由浅到深的尝试搜索同时计时，一旦超过设定的搜索时间阈值就停止搜索。当搜索过程复杂（搜索树剪枝少）实际搜索深度可能无法很深，当搜索过程简单，实际搜索深度则只受玩家设定的最大搜索深度的影响。<br>&nbsp;&nbsp;&nbsp; 迭代深化的下一层是MTD(f)的思想核心，在一个无限大的窗口中，在一个有依据的猜测值附近反复进行类似PVS的空窗探测，并不断向真实的最大局面评估值调整猜测值和窗口，直到窗口上下限闭合。</p>\n<pre><code class=\"hljs\">int MTD_f::mtdf(int firstGuess)\n&#123;\n\t/* MTD(f)窗口上下限 */\n\tint windowTop = WIN;\n\tint windowDown = -WIN;\n\t/* 空窗探测评估值，调整MTD(f)窗口的依据 */\n\tint g = firstGuess;\n\t/* alphaBeta算法的窗口上限 */\n\tint beta;\n\t/* 不断执行空窗探测直到窗口闭合，有hash置换表不怕重复搜索 */\n\twhile(windowDown &lt; windowTop)\n\t&#123;\n\t\t/* 刚调整过窗口下限，更需要通过向上偏移的空窗探测调整窗口上限 */\n\t\tif (g == windowDown)\n\t\t&#123;\n\t\t\t/* 在[g, g+1]区间上进行空窗探测 */\n\t\t\t/* alpha = g */\n\t\t\tbeta = g + 1;\n\t\t&#125;\n\t\t/* 刚调整过窗口上限，更需要通过向下偏移的空窗探测调整窗口下限 */\n\t\telse\n\t\t&#123;\n\t\t\t/* 在[g-1, g]区间上进行空窗探测 */\n\t\t\t/* alpha = g - 1 */\n\t\t\tbeta = g;\n\t\t&#125;\n\t\t/* 利用Fail-Soft AlphaBeta算法做空窗探测 */\n\t\t/* alpha = beta - 1 */\n\t\tg = TTFAlphaBeta(beta - 1, beta, 0);\n\t\t/* 根据新评估值做窗口调整 */\n\t\t/* 新评估值小于空窗口，可以认为猜高了，实际评估值应该更低 */\n\t\tif (g &lt; beta)\n\t\t&#123;\n\t\t\t/* 根据新评估值下调MTD(f)窗口上限 */\n\t\t\twindowTop = g;\n\t\t&#125;\n\t\t/* 新评估值不小于空窗口，可以认为猜低了，实际评估值应该更高 */\n\t\telse\n\t\t&#123;\n\t\t\t/* 根据新评估值上调MTD(f)窗口下限 */\n\t\t\twindowDown = g;\n\t\t&#125;\n\t&#125;\n\treturn g;\n&#125;\n</code></pre>\n<p>&nbsp;&nbsp;&nbsp; 再下一层是一个hash置换表优化的Fail-Soft-AlphaBeta算法，事实上，这个AlphaBeta的窗口大小是０，所以在我看来，MTD(f)的最下层更像一个PVS。</p>\n<h3 id=\"3-4-3-AlphaBeta\"><a href=\"#3-4-3-AlphaBeta\" class=\"headerlink\" title=\"3.4.3 AlphaBeta\"></a>3.4.3 AlphaBeta</h3><p>&nbsp;&nbsp;&nbsp; 搜索核心的另一个实现是AlphaBeta算法，实际上我只是把MTD(f)最下层的PVS拿出来，去掉置换表，把初始窗口定为无限大而已。这从算法实现方式的侧面印证了Maxmin系算法师出同门的事实。</p>\n<h2 id=\"3-5-局面评估核心\"><a href=\"#3-5-局面评估核心\" class=\"headerlink\" title=\"3.5 局面评估核心\"></a>3.5 局面评估核心</h2><p>&nbsp;&nbsp;&nbsp; 现在使用的评估方法是统计局面上棋子的自由度、受威胁程度、棋子基本价值、棋盘位置加成、棋子受保护加成，并进行简单累加。使用了很多常数作为评估依据：</p>\n<pre><code class=\"hljs\">#ifndef _EVALUATOR_H_\n#define _EVALUATOR_H_\n\n#include &quot;State.h&quot;\n#include &quot;Move.h&quot;\n#include &lt;vector&gt;\n\n/* 估值器，提供对每一个局面状态的下特定走法的评分 */\n/* 使用先验知识和一些局面评估因素为局面估值 */\nclass Evaluator\n&#123;\npublic:\n\t/* 评估结点计数 */\n\tunsigned cnt;\n\t/* 估值器构造函数，初始化估值器 */\n\tEvaluator();\n\t/* 估值函数，对给定的局面状态评分 */\n\tint evaluate(State &amp;state);\nprivate:\n\t/* 炮的一些重要坐标的加成 */\n\tconst int ADD_R_CANNON[10][9] =\n\t&#123;\n\t\t&#123;50,\t50,\t0,\t0,\t0,\t0,\t0,\t50,\t50&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t10,\t0,\t10,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t10,\t0,\t0,\t0,\t0,\t0,\t10,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;10,\t0,\t0,\t10,\t50,\t10,\t0,\t0,\t10&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;\n\t&#125;;\n\tconst int ADD_B_CANNON[10][9] =\n\t&#123;\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;10,\t0,\t0,\t10,\t50,\t10,\t0,\t0,\t10&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t10,\t0,\t0,\t0,\t0,\t0,\t10,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t10,\t0,\t10,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;50,\t50,\t0,\t0,\t0,\t0,\t0,\t50,\t50&#125;\n\t&#125;;\n\t/* 马的一些重要坐标的加成 */\n\tconst int ADD_R_KNIGHT[10][9] =\n\t&#123;\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t100,\t0,\t0,\t0,\t100,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t100,\t0,\t100,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t10,\t0,\t0,\t0,\t10,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t10,\t0,\t0,\t0,\t10,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t-100,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;\n\t&#125;;\n\tconst int ADD_B_KNIGHT[10][9] =\n\t&#123;\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t-100,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t10,\t0,\t0,\t0,\t10,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t10,\t0,\t0,\t0,\t10,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t100,\t0,\t100,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t100,\t0,\t0,\t0,\t100,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;\n\t&#125;;\n\t/* 兵的一些重要坐标的加成 */\n\tconst int ADD_R_PAWN[10][9] =\n\t&#123;\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;90,\t90,\t110,\t120,\t120,\t120,\t110,\t90,\t90&#125;,\n\t\t&#123;90,\t90,\t110,\t120,\t120,\t120,\t110,\t90,\t90&#125;,\n\t\t&#123;70,\t90,\t110,\t120,\t120,\t120,\t110,\t90,\t70&#125;,\n\t\t&#123;70,\t70,\t70,\t70,\t70,\t70,\t70,\t70,\t70&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;\n\t&#125;;\n\tconst int ADD_B_PAWN[10][9] =\n\t&#123;\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;,\n\t\t&#123;70,\t70,\t70,\t70,\t70,\t70,\t70,\t70,\t70&#125;,\n\t\t&#123;70,\t90,\t110,\t120,\t120,\t120,\t110,\t90,\t70&#125;,\n\t\t&#123;90,\t90,\t110,\t120,\t120,\t120,\t110,\t90,\t90&#125;,\n\t\t&#123;90,\t90,\t110,\t120,\t120,\t120,\t110,\t90,\t90&#125;,\n\t\t&#123;0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0&#125;\n\t&#125;;\n\t/* 先验的定义每种棋子的基本价值 */\n\tconst int BASE_VAL[32] =\n\t&#123;\n\t\t10000, 250, 250, 250, 250, 350, 350, 500, 500, 350, 350, 100, 100, 100, 100, 100,\n\t\t10000, 250, 250, 250, 250, 350, 350, 500, 500, 350, 350, 100, 100, 100, 100, 100\n\t&#125;;\n\t/* 棋子灵活度单位价值，即每个可走位置对总自由度的贡献 */\n\tconst int FREE_UNIT[32] =\n\t&#123;\n\t\t0, 1, 1, 1, 1, 12, 12, 6, 6, 6, 6, 15, 15, 15, 15, 15,\n\t\t0, 1, 1, 1, 1, 12, 12, 6, 6, 6, 6, 15, 15, 15, 15, 15\n\t&#125;;\n\t/* 棋子被威胁造成的负分 */\n\tbool threatenScore[32];\n\t/* 棋子被保护造成的加分 */\n\tbool protectScore[32];\n\t/* 棋子评分 */\n\tint chessScore[32];\n\t/* 根据特定的局面状态和当前行动权归属生成所有可能的势力覆盖方式并填充走法容器 */\n\tvoid generate(const State &amp;state);\n\t/* 棋子势力覆盖方式容器 */\n\tstd::vector&lt;Move&gt; coverList;\n&#125;;\n\n#endif\n</code></pre>\n<h1 id=\"4-手工测试\"><a href=\"#4-手工测试\" class=\"headerlink\" title=\"4 手工测试\"></a>4 手工测试</h1><p>&nbsp;&nbsp;&nbsp; 搜索深度为１时，分别使用AlphaBeta算法和MTD(f)算法作为搜索核心，评估结点数和搜索时间并没有明显的不同。两种算法下电脑的走法都很蠢。<br>&nbsp;&nbsp;&nbsp; 搜索深度为２时，使用AlphaBeta算法，绝大多数情况下评估结点数稳定在400<del>700区间内，搜索时间最多达到10^-2秒数量级；使用MTD(f)算法，绝大多数情况下评估结点数稳定在600</del>1000区间内，搜索时间稳定在0.03秒左右。<br>&nbsp;&nbsp;&nbsp; 搜索深度为３时，使用AlphaBeta算法，绝大多数情况下评估结点数稳定在10000附近，搜索时间平均在10^-2秒数量级；使用MTD(f)算法，评估结点数平均在10^3数量级上,偶尔上万，搜索时间平均在10^-2秒数量级，偶尔还会非常小。<br>&nbsp;&nbsp;&nbsp; 搜索深度为４时，使用AlphaBeta算法，评估结点数在10^5数量级上，搜索时间平均在1秒数量级，电脑的走法看起似乎比搜索３层要蠢；使用MTD(f)算法，评估结点数很少再达到10^4数量级以上，搜索时间稳定在1秒数量级，走法也有点蠢。<br>&nbsp;&nbsp;&nbsp; 搜索深度为５时，使用AlphaBeta算法，评估结点数在10^6数量级上，搜索时间平均在８秒，电脑表现比较出色，开始出现游戏崩溃的现象；使用MTD(f)算法，可能是受迭代深化的限制作用影响，评估结点数和搜索时间与搜索深度为４时很接近，但是电脑的走法比４层时更出色，会出现游戏崩溃的现象。<br>&nbsp;&nbsp;&nbsp; 搜索深度为６时，使用AlphaBeta算法，评估结点数达到了10^7数量级，搜索时间也增加到10^2秒数量级，电脑走法却不如５层时优秀，有游戏崩溃现象；使用MTD(f)算法，可能是受迭代深化的限制作用影响，评估结点数和搜索时间与搜索深度为４时很接近，电脑的走法没有比５层明显更优秀，有游戏崩溃的现象。<br>&nbsp;&nbsp;&nbsp; 更深层的搜索时AlphaBeta算法的搜索时间将长到无法忍受，游戏崩溃的现象也将更早出现。<br>&nbsp;&nbsp;&nbsp; 观察表明，使用偶数作为搜索深度时，电脑的走法性能会相对浅一层的奇数层搜索结果有一定的衰减，迭代深化时的层数步进也许设置为２更好。</p>\n<h1 id=\"5-结论与收获\"><a href=\"#5-结论与收获\" class=\"headerlink\" title=\"5 结论与收获\"></a>5 结论与收获</h1><p>&nbsp;&nbsp;&nbsp; 过去谈及棋牌游戏的人机博弈我都只能表示佩服，满怀憧憬的感叹一下，表示做起来可能很麻烦。真的动手做过一个粗糙的练习之后才发现，用的无非还是那些简单算法的扩展或变种，简单说起来也不过是有限搜索树而已。不过种种精细的剪枝与优化还是很磨练人的心性的，当然我还没磨练到位，毕竟初版的优化我都没做彻底就来写博文了。</p>\n<h1 id=\"6-不足与展望\"><a href=\"#6-不足与展望\" class=\"headerlink\" title=\"6 不足与展望\"></a>6 不足与展望</h1><p>&nbsp;&nbsp;&nbsp; 不足：</p>\n<ul>\n<li>当前版本的两个搜索核心都是盲目搜索，即搜索中容易导致剪枝或棋局结束的结点没有优先搜索。</li>\n<li>局面评估核心应该重构，提供一个通用接口，为神经网络优化或其他技术优化的评估核心做准备。</li>\n<li>搜索树的展开过程中仍然存在动态申请内存空间的动作，当搜索深度到达４，偶尔会出现内存申请失败，游戏崩溃的情况，可以尽量静态的一次性的申请内存。</li>\n<li>没有足够优秀的查表优化。</li>\n</ul>\n<p>&nbsp;&nbsp;&nbsp; 展望：</p>\n<ul>\n<li>通用部件的数据结构还可以进一步细化优化。</li>\n<li>走法生成器和评估核心的工具函数——棋子影响力覆盖范围生成器都有并行化的优化空间。</li>\n<li>局面评估核心还可以有更优秀的，基于机器学习的优化。</li>\n<li>还可以建立适当规模的开局库、残局库。</li>\n</ul>\n<p>&nbsp;&nbsp;&nbsp; 最后，挂<a href=\"https://github.com/bipedalBit/BipedalBit-Chinese-Chess\">Git项目地址</a>。<br>&nbsp;&nbsp;&nbsp; 因为偶尔偷懒，项目代码规范化有些参差不齐，有好的建议欢迎讨论。</p>\n",
            "tags": [
                "Qt",
                "C++",
                "人机博弈",
                "AlphaBeta",
                "MTD(f)"
            ]
        },
        {
            "id": "https://bipedalbit.net/2015/11/14/%E4%BA%BA%E6%9C%BA%E5%8D%9A%E5%BC%88%E5%88%9D%E6%8E%A2/",
            "url": "https://bipedalbit.net/2015/11/14/%E4%BA%BA%E6%9C%BA%E5%8D%9A%E5%BC%88%E5%88%9D%E6%8E%A2/",
            "title": "人机博弈初探",
            "date_published": "2015-11-14T14:27:47.000Z",
            "content_html": "<p>&nbsp;&nbsp;&nbsp; 组里布置任务，要编个中国象棋人机博弈程序练练手，写这篇文时游戏初版已经完成了。开工前导师给了些相关资料，我自己又稍微做了些调查，这篇文就先来对人机博弈，尤其是棋牌游戏的人机博弈思路做一些概念上的科普铺垫。做好了概念铺垫，下一篇再挑重点简单讲解下我的中国象棋游戏实现情况。</p>\n<span id=\"more\"></span>\n<p>&nbsp;&nbsp;&nbsp; 其实人工智能课的大作业也是要写个概念总结，我干脆把那篇改改贴上来。</p>\n<h1 id=\"1-博弈树搜索算法\"><a href=\"#1-博弈树搜索算法\" class=\"headerlink\" title=\"1 博弈树搜索算法\"></a>1 博弈树搜索算法</h1><p>&nbsp;&nbsp;&nbsp; 人机博弈的过程实质上是对博弈树——一种状态树的搜索，是一种博弈论中的重复博弈过程。博弈树与状态树的不同之处在于，对每一层搜索来说，目标状态会有区别，如果第奇数层搜索的目标是寻找对电脑来说最好的搜索状态，那么第偶数层的搜索中，目标状态则应该是人类行动可能导致的新状态。这种搜索算法不能单纯等同于图论中对状态树的深度或广度优先搜索算法，但是与传统的状态树搜索算法有莫大的渊源。</p>\n<h2 id=\"1-1-极大极小值算法（Minmax-Algorithm）\"><a href=\"#1-1-极大极小值算法（Minmax-Algorithm）\" class=\"headerlink\" title=\"1.1 极大极小值算法（Minmax Algorithm）\"></a>1.1 极大极小值算法（Minmax Algorithm）</h2><p>&nbsp;&nbsp;&nbsp; 极大极小值算法是一系列改进的博弈树搜索算法的最原始的基础。它的基本思想是，在每层搜索前评估状态结点，在博弈树首层搜索一个评估值最大的状态结点作为电脑选择的最优行动方式，那么下一层就搜索评估值最小的状态结点来模拟人类对手的行动。重复这一博弈过程的博弈树搜索算法就称为极大极小值算法。<br>&nbsp;&nbsp;&nbsp; 在棋类游戏中，人机博弈搜索算法通常是基于深度优先搜索的。因为如果使用广度优先算法来遍历博弈树，内存中的状态结点将迅速变多，马上耗尽所有可用的内存空间。而深度优先搜索的过程中，向搜索树根结点回溯时会释放原本占用的栈空间。这使得搜索算法的内存开销只与搜索深度线性相关。</p>\n<h2 id=\"1-2-负极大值算法（Negamax-Algorithm）\"><a href=\"#1-2-负极大值算法（Negamax-Algorithm）\" class=\"headerlink\" title=\"1.2 负极大值算法（Negamax Algorithm）\"></a>1.2 负极大值算法（Negamax Algorithm）</h2><p>&nbsp;&nbsp;&nbsp; 负极大值算法是对极大极小值算法的简单改进。当准备模拟人类行动，不去找评估值最小的状态结点，而是依旧寻找评估值最大的状态结点，只是在向搜索树上一层反馈搜索结果（最大评估值）时，进行一次正负翻转。这样一来可以通过引入带符号的状态评估值，简化最大最小值算法的形式。实际上，这种优化算法与最大最小值算法相比并没有效率上的不同。</p>\n<h2 id=\"1-3-Alpha-Beta搜索\"><a href=\"#1-3-Alpha-Beta搜索\" class=\"headerlink\" title=\"1.3 Alpha-Beta搜索\"></a>1.3 Alpha-Beta搜索</h2><p>&nbsp;&nbsp;&nbsp; 搜索算法中最常见的优化手段就是对搜索树的剪枝，Alpha-Beta搜索算法就是一种剪枝优化的最大最小值算法。在朴素的极大极小值搜索算法中，每一层对最大最小值的搜索都是盲目而不加限制的。如果子状态结点的搜索返回值可以被利用起来，用来截断后续搜索过程，就可以实现搜索树的剪枝了。负极大值形式的Alpha-Beta搜索算法中只有Beta剪枝这一种剪枝（通过评估值的正负翻转将Alpha剪枝也并入了Beta剪枝）。<br>&nbsp;&nbsp;&nbsp; 具体来说是事先提供一个无限大的搜索窗口，搜索过程中每反馈一个状态评估值，更新最大评估值记录，并使用-Beta和这个还不大于Beta的最大评估值的翻转值-Alpha分别作为子状态结点的搜索窗口下限和上限。当这个记录值增长到不小于当前搜索状态的搜索窗口上限，也就是Beta值时，判定搜索树已生长至叶结点，立即进行Beta剪枝，终止搜索，返回这个最大值，以供上层状态结点调整搜索窗口。<br>&nbsp;&nbsp;&nbsp; 自1928年极大极小值算法诞生以来，出现了各种改进算法，而当前最优秀的博弈树搜索算法，绝大多数都以Alpha-Beta算法为基础。可以说，Alpha-Beta算法是现代博弈树搜索算法的基础技术，也是之后各种优化算法最合适的入门铺垫。</p>\n<h2 id=\"1-4-Fail-Soft-Alpha-Beta搜索\"><a href=\"#1-4-Fail-Soft-Alpha-Beta搜索\" class=\"headerlink\" title=\"1.4 Fail-Soft Alpha-Beta搜索\"></a>1.4 Fail-Soft Alpha-Beta搜索</h2><p>&nbsp;&nbsp;&nbsp; 从算法的名字不难看出，Fail-Soft Alpha-Beta算法是对Alpha-Beta算法的优化。操作系统中，内存调度范畴最意义重大的技术可以说就是缓存。缓存的核心思想——数据访问的空间局部性，也可以引申到博弈树搜索技术中来。<br>&nbsp;&nbsp;&nbsp; 之前提到的Alpha-Beta算法中的搜索窗口一开始是无限大的。其实在大部分情况下，这个初始窗口可以更小一些，当然一旦缩小的初始窗口，就存在评估值落在窗口外的危险。那么万一评估值落在窗口外（上方或下方），就只有加入一个无限大或无限小的窗口上／下限，再重新搜索了。</p>\n<h2 id=\"1-5-渴望搜索（Aspiration-Search）\"><a href=\"#1-5-渴望搜索（Aspiration-Search）\" class=\"headerlink\" title=\"1.5 渴望搜索（Aspiration Search）\"></a>1.5 渴望搜索（Aspiration Search）</h2><p>&nbsp;&nbsp;&nbsp; 鉴于搜索窗口是一个十分优秀的剪枝思路，渴望搜索同样是对搜索窗口的优化。Fail-Soft Alpha-Beta搜索中初始窗口的定义还带有盲目性，而渴望搜索正是针对这一点的优化。实际上，渴望搜索的初始搜索窗口是以一个特定值为中心，以另一个特定值为半径（正负方向偏差值）来定义的。这样一来，这个搜索窗口的中心就显得尤为重要。通常选用上一次搜索的最终状态评估值作为窗口中心是比较有效的，因为相邻的两次最优行动方式通常非常接近。</p>\n<h2 id=\"1-6-极小窗口搜索（Minimal-Window-Search-PVS）\"><a href=\"#1-6-极小窗口搜索（Minimal-Window-Search-PVS）\" class=\"headerlink\" title=\"1.6 极小窗口搜索（Minimal Window Search&#x2F;PVS）\"></a>1.6 极小窗口搜索（Minimal Window Search&#x2F;PVS）</h2><p>&nbsp;&nbsp;&nbsp; 前面提到过，相邻的两次最优行动方式通常非常接近。PVS正是利用这一事实很极端的将渴望搜索的搜索窗口进一步缩小到了以1为尺寸。更小的初始窗口将印发更多的剪枝，而统计数据证明，大多数情况下PVS的搜索效率确实比渴望搜索更高。</p>\n<h2 id=\"1-7-置换表优化的搜索算法\"><a href=\"#1-7-置换表优化的搜索算法\" class=\"headerlink\" title=\"1.7 置换表优化的搜索算法\"></a>1.7 置换表优化的搜索算法</h2><p>&nbsp;&nbsp;&nbsp; 状态搜索过程中，有时会遇到曾经搜索过的状态，这时如果重新搜索显然是不划算的。如果把搜索过的状态都结构化的记录下来，就可以在一些特定情况下提前截断搜索过程。这就是置换表的思路。要对搜索算法进行置换表的优化，置换表就必须提供足够快的查表速度，最快的查找技术无非就是哈希查找了。这就组成了一个用置换表优化搜索算法的完整解决方案。</p>\n<h2 id=\"1-8-迭代深化的搜索算法\"><a href=\"#1-8-迭代深化的搜索算法\" class=\"headerlink\" title=\"1.8 迭代深化的搜索算法\"></a>1.8 迭代深化的搜索算法</h2><p>&nbsp;&nbsp;&nbsp; 实际人类博弈场景中，博弈的外部限制条件往往与思考的深度无关，而与思考的时间有关。那么在搜索博弈树的过程中，可以迭代的逐步加深搜索深度，直到搜索时间超过阈值。显然这种优化将导致搜索深度不稳定，也使得搜索性能的稳定性不能得到保证。但在模拟人类博弈行为的场景下，迭代深化优化的搜索算法能使机器的行为更接近人类。</p>\n<h2 id=\"1-9-启发式搜索策略\"><a href=\"#1-9-启发式搜索策略\" class=\"headerlink\" title=\"1.9 启发式搜索策略\"></a>1.9 启发式搜索策略</h2><p>&nbsp;&nbsp;&nbsp; 盲目搜索策略是被动的，不管如何调整搜索窗口，总是难以避免一些冗余的搜索项。如果在搜索时增加一些启发因素，将有利搜索快速完成的子状态的搜索过程提前，也许可以提前剪枝或提前结束搜索。如果获取启发因素的场景发生在比较靠前的搜索过程中，这就是历史启发的搜索优化思路。</p>\n<h2 id=\"1-10-MTD-f-搜索\"><a href=\"#1-10-MTD-f-搜索\" class=\"headerlink\" title=\"1.10 MTD(f)搜索\"></a>1.10 MTD(f)搜索</h2><p>&nbsp;&nbsp;&nbsp; MTD(f)搜索的全称是Memory-enhanced Test Driver with node n and value f，大意是记忆（置换表）优化、测试（空窗探测）驱动的搜索算法。MTD(f)算法将PVS的极小窗口干脆改成了空窗口，即单个猜测值就是一个窗口。只进行一些浅层的搜索后，就可以得到一个真实的极大评估值。这个评估值一定会落在猜测值的一侧，那么就可以利用这一点来不断进行猜测（空窗探测）并调整猜测值的取值范围，直到猜测值的范围闭合，即是得到了最终评估值。有不少实践者称MTD(f)算法在国际象棋、西洋跳棋等人机博弈应用场景中比PVS更优秀。</p>\n<h2 id=\"1-11-疑惑与思考\"><a href=\"#1-11-疑惑与思考\" class=\"headerlink\" title=\"1.11 疑惑与思考\"></a>1.11 疑惑与思考</h2><p>&nbsp;&nbsp;&nbsp; 相信有的读者已经发觉，上述搜索算法只在叶结点做局面评估恐怕不太妥当。其实我也是这么认为的。<br>&nbsp;&nbsp;&nbsp; 上述搜索算法都建立在Maxmin算法中一个大前提的基础上：不论对手还是自己，下棋的人会尝试让棋局在若干步内到达这若干步内可能的最好的一个局面。<br>&nbsp;&nbsp;&nbsp; 事实上，下棋时，我们在选择下一步时，并不是总是想要逼近某个特定的局面，除非这个局面是一个抛给对手的陷阱。<br>&nbsp;&nbsp;&nbsp; 在象棋、国际象棋这类棋子数单调减少，局面复杂程度变化小的棋类游戏中确实大部分局面中玩家都在不断互相抛出吃子陷阱。但是在局面复杂程度逐渐增加的棋类游戏如五子棋和围棋的中，我们在大部分局面中思考的往往是更模糊的趋势问题，或者说概率问题。我们需要在海量的局面演变路径中归结出当前走法应该将局面引向的最好的方向而不是某一条具体路径，同时依旧需要立即规避致命的陷阱。各个因素对结论的影响的归结，这显然应该是一个关于结论修正和因素采纳权重的问题。<br>&nbsp;&nbsp;&nbsp; 在中国象棋、国际象棋中，Minmax的下棋思路应该在大部分情况下是合理而恰当的。然而在五子棋的部分局面中，和围棋的更多局面中，Minmax算法的思路前提根本就是不合理的。也就是说，不是基于Minmax的算法的性能不足以胜任围棋的搜索算法，而是Minmax应用在围棋走法搜索中时会犯很多方向性错误，这些错误的积累造成的不良影响已经大到不能被接受了。<br>&nbsp;&nbsp;&nbsp; 下面我们将引入的MC-UCT算法，中文描述的算法名称是“树图置信”，“置信”这个概念跟我前面提到的因素归结、因素权重问题不谋而合。<br>&nbsp;&nbsp;&nbsp; 我们对“置信”方法的需求的来源，是局面复杂程度不稳定的情况下局面走向的不明朗和难以把控。<br>&nbsp;&nbsp;&nbsp; 相反，我们对Minmax思路的需求的前提，是局面明朗的情况下，我们很清楚该把局面引向哪些特定的状态。<br>&nbsp;&nbsp;&nbsp; 以上思考引发的我的另一个思考是，围棋这种实际问题中，棋盘大小仍然是有限的，也就是说，局面的复杂度终究会稳定在一个区间中。那么当局面稳定下来，我们对正确的“局面变化趋势的引导”的需求就降低了很多。因为我们改变局面变化趋势的发挥空间已经太小，这时问题的性质发生了改变，事实上，这时已经进入了围棋的“收官”阶段。一个局面稳定的围棋残局的处理，已经十分类似象棋类的棋类游戏，甚至比象棋更简单，更好处理。这种情况下放弃UCT，转而使用Minmax的算法思路反而是更恰当的。</p>\n<h2 id=\"1-12-UCT算法\"><a href=\"#1-12-UCT算法\" class=\"headerlink\" title=\"1.12 UCT算法\"></a>1.12 UCT算法</h2><p>&nbsp;&nbsp;&nbsp; 下面我们来看下UCT的算法执行过程：</p>\n<ul>\n<li>(1) 从博弈树的根点开始向下搜索，执行(2)。</li>\n<li>(2) 遇到结点a后，若a存在从未评估过的子结点，执行(3)，否则执行(4)。</li>\n<li>(3) 通过蒙特卡罗方法（这里先按下不表，后面会介绍，但这种评估方法是“置信”的来源）评估该子结点，得到收益值后更新该子结点至根结点路径上所有结点的平均收益值，执行(1)。</li>\n<li>(4) 计算每个子结点的UCB值（通过特殊结论将从蒙特卡罗方法中获得的收益值转换为新一轮搜索的置信基础值），将UCB值最高的子结点作为结点a，执行(2)。</li>\n<li>(5) 算法可随时终止，通常达到给定时间或尝试次数后终止。<br>&nbsp;&nbsp;&nbsp; UCT算法最让人欣赏的两点是使用置信的蒙特卡罗评估，以及评估值的回溯更新。</li>\n</ul>\n<h1 id=\"2-评估函数\"><a href=\"#2-评估函数\" class=\"headerlink\" title=\"2 评估函数\"></a>2 评估函数</h1><h2 id=\"2-1-传统评估函数的优化\"><a href=\"#2-1-传统评估函数的优化\" class=\"headerlink\" title=\"2.1 传统评估函数的优化\"></a>2.1 传统评估函数的优化</h2><p>&nbsp;&nbsp;&nbsp; 在搜索博弈树子状态的过程中，需要对位于博弈树叶结点位置的子状态给出评估值。传统的，可以从已有知识、经验中挖掘出状态评估因素。为各因素加上先验的权值后就可以为博弈树的子状态提供一个评估值。然而这种评估模式还有很大的优化空间。尤其是在调整估值因素的权重方面。</p>\n<h3 id=\"2-1-1-爬山法\"><a href=\"#2-1-1-爬山法\" class=\"headerlink\" title=\"2.1.1 爬山法\"></a>2.1.1 爬山法</h3><p>&nbsp;&nbsp;&nbsp; 猜测一个较好的初始权重后，逐步微调权重，直到评估效果达到一个极大值，这就是爬山法。显然爬山法非常依赖一个优秀的初始猜测权重，而且寻找最优权重的过程会很缓慢。</p>\n<h3 id=\"2-1-2-蒙特卡罗方法\"><a href=\"#2-1-2-蒙特卡罗方法\" class=\"headerlink\" title=\"2.1.2 蒙特卡罗方法\"></a>2.1.2 蒙特卡罗方法</h3><p>&nbsp;&nbsp;&nbsp; 既然初始权重或寻找起点是爬山法的短板，那么就进行足够多次的爬山法，使爬山法的起点覆盖足够多的情况，最后汇总寻找结果。这就是蒙特卡罗方法的基本思路。</p>\n<h3 id=\"2-1-3-模拟退火算法\"><a href=\"#2-1-3-模拟退火算法\" class=\"headerlink\" title=\"2.1.3 模拟退火算法\"></a>2.1.3 模拟退火算法</h3><p>&nbsp;&nbsp;&nbsp; 模拟退火算法是对蒙特卡罗方法的改进，它使用MetroPolis重要性采样的基本思想，在寻优的开始使用较高的概率进行随机突跳,随着寻优过程的深入逐步降低这一接受不佳参数概率。并且随着搜索的深入,可接受的参数的不佳程度也越来越小。通过这样一个由粗到细的过程逐渐逼近最优的参数。由于此算法要求对参数的改变概率逐渐下降及对各种参数值进行充分多次的采样,在实际使用中也比爬山法的速度要慢,但比蒙特卡罗方法要快。</p>\n<h3 id=\"2-1-4-遗传算法\"><a href=\"#2-1-4-遗传算法\" class=\"headerlink\" title=\"2.1.4 遗传算法\"></a>2.1.4 遗传算法</h3><p>&nbsp;&nbsp;&nbsp; 顾名思义，遗传算法将各个评估因素的权重作为”遗传基因”，在有限大小的变异程度下，尝试并继承更优秀的权重组合。通过模拟进化过程寻找最优权重。</p>\n<h3 id=\"2-1-5-人工神经网络\"><a href=\"#2-1-5-人工神经网络\" class=\"headerlink\" title=\"2.1.5 人工神经网络\"></a>2.1.5 人工神经网络</h3><p>&nbsp;&nbsp;&nbsp; BP神经网络模拟了神经系统中神经元的刺激积累和交互网状影响的作用，训练一套合理的神经元间连接的信息采样权重。这与获得最优权重的目的不谋而合。或许为了提高训练性能，还可以用上CNN（卷积神经网络）、BDN（置信深度网络）这样的深度学习神经网络。</p>\n<h2 id=\"2-2-蒙特卡罗方法的评估算法\"><a href=\"#2-2-蒙特卡罗方法的评估算法\" class=\"headerlink\" title=\"2.2 蒙特卡罗方法的评估算法\"></a>2.2 蒙特卡罗方法的评估算法</h2><p>&nbsp;&nbsp;&nbsp; 计算机围棋博弈问题的一大难点在于难以设计简单有效的局面评估算法。传统的围棋程序主要采用影响函数等专家知识进行局面评估，由于围棋的专家知识难以抽象出来（如厚味，薄味，气合等词），往往评估得不准。那么精确评估似乎只有穷举了。如果黑白双方的接下来每手棋都“正确”，最后黑棋赢了，那么当时的局面一定是黑棋优势。可惜如果没有量子计算机，这种穷举是无法达成的。<br>&nbsp;&nbsp;&nbsp; 再假设，如果黑白双方棋力不高却相当，来续下这个局面，最后是黑棋赢了，当时的局面是谁优势呢？你大概会说，黑棋优势的可能性更大一些。进一步，同样的局面续下了1000次，有800次是黑棋赢了，那么有理由基本相信，当前局面中黑棋占优。<br>&nbsp;&nbsp;&nbsp; 那么，如果黑棋和白棋都不会围棋，只会随机落子呢？他们针对这一局面续下了1000次，竟然有800次是黑棋赢了。这时我们也可以断言，当前局面确实黑棋占优。<br>&nbsp;&nbsp;&nbsp; 这就是蒙特卡罗局面评估算法，简单点说，就是用大量迭代的随机的深度优先搜索来代替先验知识对局面做出评估。当然大量彼此没有同步约束的随机迭代过程就很适合且只适合通过并行方式甚至分布式集群计算来解决了。</p>\n",
            "tags": [
                "人机博弈",
                "Maxmin",
                "AlphaBeta",
                "PVS",
                "MTD(f)"
            ]
        }
    ]
}